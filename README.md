# PySpark Programming - Taming Big Data with Spark and Python


<p align="center">  
    <br>
	<a href="#">
        <img height=100 src="./SparkCourse/img/spark.png" alt="Spark" title="Spark" hspace=80> 
  </a>	
</p>
 <br>
 
The course in PySpark programming has helped me to learn the basics of Spark (v3.3) infrastructure and how spark can process data in stand-alone machine or on cluster running on AWS EMR (using YARN manager). Below features have been covered as foundations to my learning:
<br>

- RDD (Resilient Distributed Datasets)
- Spark SQL
- DataFrame APIs
- Spark ML - Processing movie recommendations data using machine learning models like ALS (Alternative Least Square) and Logistic Regression.
